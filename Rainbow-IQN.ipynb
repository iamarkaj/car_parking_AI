{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementing Rainbow-IQN\n",
    "   a Reinforcement Learning algorithm\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = False # set load = True to resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(1337)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import gc\n",
    "import io\n",
    "import cv2\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from IPython.display import clear_output\n",
    "import socket\n",
    "import time\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(object):\n",
    "    \n",
    "    def __init__(self, capacity, load, alpha=0.6):\n",
    "        self.capacity   = capacity\n",
    "        self.alpha      = alpha\n",
    "        if load:\n",
    "            self.buffer     = np.array(np.load(\"store/buffer.npy\", allow_pickle=True), dtype= np.float32)\n",
    "            self.priorities = np.array(np.load(\"store/priorities.npy\", allow_pickle=True), dtype=np.float32)\n",
    "            self.position   = int(np.load(\"store/position.npy\", allow_pickle=True))\n",
    "        else: \n",
    "            self.buffer     = np.array([(0,0,0,0)], dtype= np.float32)\n",
    "            self.priorities = np.zeros((self.capacity), dtype= np.float32)\n",
    "            self.position   = 0\n",
    "            \n",
    "    def push(self, current_state, action, new_state, reward):   \n",
    "        self.priorities[self.position] = self.priorities.max() if len(self.buffer) else 1.0    \n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer = np.vstack((self.buffer, (current_state, action, new_state, reward)))\n",
    "        else:\n",
    "            self.buffer[self.position] = (current_state, action, new_state, reward)   \n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        return \n",
    "            \n",
    "    def sample(self, size, beta=0.4):\n",
    "        prios       = self.priorities[:] if len(self.buffer) == self.capacity else self.priorities[:self.position]\n",
    "        prios       = prios**self.alpha\n",
    "        prios       = np.nan_to_num(prios)\n",
    "        prios_sum   = np.sum(prios)\n",
    "        prios       = prios / prios_sum\n",
    "        prb         = None if np.isnan(prios).any() else prios\n",
    "        indices     = np.random.choice(len(self.buffer), size, p=prb)\n",
    "        states      = [self.buffer[id][0] for id in indices]\n",
    "        actions     = [self.buffer[id][1] for id in indices]\n",
    "        next_states = [self.buffer[id][2] for id in indices]\n",
    "        rewards     = [self.buffer[id][3] for id in indices]\n",
    "        total       = len(self.buffer)\n",
    "        weights     = np.array([(total * prios[id]) ** (-beta) for id in indices], dtype=np.float32)\n",
    "        weights_max = weights.max()\n",
    "        weights     = weights / weights_max\n",
    "        return states, actions, next_states, rewards, indices, weights\n",
    "        \n",
    "    def update_priorities(self, batch_idx, batch_prios):  \n",
    "        for b_idx, b_prios in zip(batch_idx, batch_prios):    \n",
    "            self.priorities[b_idx] = b_prios\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, std_init=0.4):\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        self.in_features  = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init     = std_init\n",
    "        self.weight_mu    = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        self.register_buffer('weight_epsilon', torch.FloatTensor(out_features, in_features))\n",
    "        self.bias_mu      = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.bias_sigma   = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.register_buffer('bias_epsilon', torch.FloatTensor(out_features))\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        weight = self.weight_mu + self.weight_sigma.mul(self.weight_epsilon)\n",
    "        bias   = self.bias_mu   + self.bias_sigma.mul(self.bias_epsilon)\n",
    "        return F.linear(x, weight, bias)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        mu_range = 1 / sqrt(self.weight_mu.size(1))\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(self.std_init / sqrt(self.weight_sigma.size(1)))\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(self.std_init / sqrt(self.bias_sigma.size(0)))\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        epsilon_in  = self._scale_noise(self.in_features)\n",
    "        epsilon_out = self._scale_noise(self.out_features)\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(self._scale_noise(self.out_features))\n",
    "    \n",
    "    def _scale_noise(self, size):\n",
    "        x = torch.randn(size)\n",
    "        x = x.sign().mul(x.abs().sqrt())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(nn.Module): \n",
    "    \n",
    "    def __init__(self, input_shape, num_atoms, num_actions = 4):\n",
    "        super(Agent, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_actions = num_actions\n",
    "        self.num_atoms   = num_atoms\n",
    "        self.features    = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size = 8, stride = 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size = 4, stride = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size = 3, stride = 1),\n",
    "            nn.ReLU())\n",
    "        self.noisy_value1     = NoisyLinear(self.features_size(), 512)\n",
    "        self.noisy_value2     = NoisyLinear(512, self.num_atoms)\n",
    "        self.noisy_advantage1 = NoisyLinear(self.features_size(), 512)\n",
    "        self.noisy_advantage2 = NoisyLinear(512, self.num_atoms * self.num_actions)\n",
    "        \n",
    "    def features_size(self):\n",
    "        return self.features(torch.zeros(1, *self.input_shape)).view(1, -1).size(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x          = self.features(x)\n",
    "        x          = x.view(batch_size, -1) \n",
    "        value      = F.relu(self.noisy_value1(x))\n",
    "        value      = self.noisy_value2(value)\n",
    "        advantage  = F.relu(self.noisy_advantage1(x))\n",
    "        advantage  = self.noisy_advantage2(advantage)\n",
    "        value      = value.view(batch_size, 1, self.num_atoms)\n",
    "        advantage  = advantage.view(batch_size, self.num_actions, self.num_atoms)\n",
    "        x          = value + advantage - advantage.mean(1, keepdim=True)\n",
    "        x          = x.view(-1, self.num_actions, self.num_atoms)\n",
    "        return x\n",
    "        \n",
    "    def reset_noise(self):\n",
    "        self.noisy_value1.reset_noise()\n",
    "        self.noisy_value2.reset_noise()\n",
    "        self.noisy_advantage1.reset_noise()\n",
    "        self.noisy_advantage2.reset_noise()\n",
    "        \n",
    "    def act(self, state, epsilon):\n",
    "        if np.random.rand() > epsilon:\n",
    "            with torch.no_grad():\n",
    "                state   = torch.FloatTensor(state).unsqueeze(0)\n",
    "            qvalues = self.forward(state).mean(2)\n",
    "            action  = qvalues.max(1)[1]\n",
    "            action  = action.data.cpu().numpy()[0]\n",
    "        else:\n",
    "            action  = np.random.randint(self.num_actions)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(current_model, target_model):\n",
    "    target_model.load_state_dict(current_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_td_loss(batch_size, beta):\n",
    "    state, action, next_state, reward, indices, weights = replay_buffer.sample(batch_size, beta) \n",
    "    state      = torch.FloatTensor(np.float32(state))\n",
    "    action     = torch.LongTensor(action)\n",
    "    next_state = torch.FloatTensor(np.float32(next_state))\n",
    "    reward     = torch.FloatTensor(reward)\n",
    "    weights    = torch.FloatTensor(weights)\n",
    "    theta      = current_model(state)[np.arange(batch_size), action]\n",
    "    Znext      = target_model(next_state).detach()\n",
    "    Znext_max  = Znext[np.arange(batch_size), Znext.mean(2).max(1)[1]]\n",
    "    Ttheta     = reward.unsqueeze(1) + gamma * Znext_max\n",
    "    diff       = Ttheta.t().unsqueeze(-1) - theta \n",
    "    huber_diff = torch.where(diff.abs() < 1, 0.5 * diff.pow(2), 1 * (diff.abs() - 0.5 * 1))\n",
    "    loss       = huber_diff * (tau - (diff.detach() < 0).float()).abs()\n",
    "    loss       = loss.mean()\n",
    "    prios      = loss * weights + 1e-3\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    replay_buffer.update_priorities(indices, prios.data.cpu().numpy())\n",
    "    nn.utils.clip_grad_norm_(current_model.parameters(), 0.5)\n",
    "    optimizer.step()\n",
    "    current_model.reset_noise()\n",
    "    target_model.reset_noise()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title(f'Frame: {frame_idx}')\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('Loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(binary_data):\n",
    "    x = None\n",
    "    x = Image.open(io.BytesIO(binary_data)) \n",
    "    x = np.array(x)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2GRAY)\n",
    "    x = cv2.resize(x, (input_shape[1], input_shape[2]))\n",
    "    x = x / 255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    torch.save(current_model, \"E:/Jupyter files/REINFORCEMENT LEARNIING/CarParkingAI/store/current_model\")\n",
    "    torch.save(target_model, \"E:/Jupyter files/REINFORCEMENT LEARNIING/CarParkingAI/store/target_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    current_model = torch.load(\"E:/Jupyter files/REINFORCEMENT LEARNIING/CarParkingAI/store/current_model\")\n",
    "    target_model  = torch.load(\"E:/Jupyter files/REINFORCEMENT LEARNIING/CarParkingAI/store/target_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_start     = 0.4\n",
    "beta_frames    = 10_000\n",
    "update_beta    = lambda frame_idx: min(1.0, beta_start + frame_idx * (1.0 - beta_start) / beta_frames)\n",
    "\n",
    "epsilon_decay  = 0.002\n",
    "min_epsilon    = 0.1\n",
    "update_epsilon = lambda frame_idx: min_epsilon + (1.0 - min_epsilon) * np.exp(-epsilon_decay * frame_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape         = (4, 84, 84)\n",
    "num_actions         = 4\n",
    "BATCH_SIZE          = 256\n",
    "MINI_BATCH_SIZE     = 32\n",
    "gamma               = 0.99\n",
    "num_atoms           = 51\n",
    "computes_loss_after = 4\n",
    "plot_after          = 10\n",
    "copy_weights_after  = 100\n",
    "MIN_REPLAY_SIZE     = 20_000\n",
    "tau                 = torch.Tensor((2 * np.arange(num_atoms) + 1) / (2.0 * num_atoms)).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = Agent(input_shape, num_atoms, num_actions)\n",
    "target_model  = Agent(input_shape, num_atoms, num_actions)\n",
    "update_target(current_model, target_model)\n",
    "\n",
    "optimizer     = optim.Adam(current_model.parameters(), lr=0.0001)\n",
    "\n",
    "replay_buffer = PrioritizedReplayBuffer(200_000, load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def main(load):\n",
    "    \n",
    "    counter     = int(np.load(\"store/counter.npy\", allow_pickle=True)) if load else 0    \n",
    "    epsilon     = 1.0\n",
    "    all_rewards = np.array([])\n",
    "    losses      = np.array([])\n",
    "        \n",
    "    print(\"[SERVER] Starting ...\") \n",
    "    s = socket.socket()\n",
    "    s.bind(('127.0.0.1', 8010))\n",
    "    s.listen()\n",
    "    while True:\n",
    "        c, addr = s.accept()\n",
    "        try:\n",
    "            while True:\n",
    "                counter       = counter + 1\n",
    "                total_rewards = 0\n",
    "\n",
    "                c.sendall(\"1\".encode('ascii')) # send 1 to start receiving data\n",
    "                for batch_num in range(BATCH_SIZE):\n",
    "                    old_frame_state = np.zeros(input_shape)\n",
    "                    new_frame_state = np.zeros(input_shape)\n",
    "                    for frame_num in range(input_shape[0]):\n",
    "                        old_frame_len = c.recv(15).decode('utf-8')  #receive old image len first\n",
    "                        old_frame     = c.recv(int(old_frame_len))  #receive old image\n",
    "                        old_frame_state[frame_num] = preprocess_frame(old_frame)\n",
    "                    action = current_model.act(old_frame_state, epsilon)\n",
    "                    epsilon = update_epsilon(counter)\n",
    "                    c.sendall(str(action).encode('ascii'))  #send action\n",
    "                    for frame_num in range(input_shape[0]):\n",
    "                        new_frame_len = c.recv(15).decode('utf-8')  #receive image len first\n",
    "                        new_frame     = c.recv(int(new_frame_len))  #receive image\n",
    "                        new_frame_state[frame_num] = preprocess_frame(new_frame)\n",
    "                    reward = float(c.recv(10).decode('utf-8')) / 20  #receive reward\n",
    "                    replay_buffer.push(old_frame_state, action, new_frame_state, reward)\n",
    "                    total_rewards += reward\n",
    "                    del old_frame, new_frame, old_frame_state, new_frame_state\n",
    "                    gc.collect()\n",
    "                c.sendall(\"0\".encode('ascii')) # send 0 to stop receiving data\n",
    "\n",
    "\n",
    "                all_rewards = np.append(all_rewards, total_rewards)\n",
    "\n",
    "\n",
    "                if len(replay_buffer) > MIN_REPLAY_SIZE:\n",
    "                    if counter % computes_loss_after == 0:\n",
    "                        beta   = update_beta(counter)\n",
    "                        loss   = compute_td_loss(MINI_BATCH_SIZE, beta)\n",
    "                        losses = np.append(losses, loss.item())\n",
    "                    if counter % copy_weights_after == 0: \n",
    "                        update_target(current_model, target_model)   \n",
    "                    if counter % plot_after == 0: \n",
    "                        plot(counter, all_rewards, losses)\n",
    "                else:\n",
    "                    print(counter)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "        finally:\n",
    "            np.save(\"store/counter.npy\", counter)\n",
    "            np.save(\"store/position.npy\", replay_buffer.position)\n",
    "            np.save(\"store/buffer.npy\", replay_buffer.buffer)\n",
    "            np.save(\"store/priorities.npy\", replay_buffer.priorities)\n",
    "            save_model()\n",
    "            gc.collect()\n",
    "            c.close()\n",
    "            return\n",
    "\n",
    "    print(\"[SERVER] Stoping ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
